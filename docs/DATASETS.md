# Veri Seti KÄ±lavuzu

Bu dokÃ¼mantasyon, BioGNN ile kullanÄ±labilecek multimodal biyometrik veri setlerini ve bunlarÄ± nasÄ±l hazÄ±rlayacaÄŸÄ±nÄ±zÄ± aÃ§Ä±klar.

## ğŸ“¥ Otomatik Veri Seti Ä°ndirme

BioGNN, birÃ§ok popÃ¼ler biyometrik veri setini otomatik olarak indirmek iÃ§in yerleÅŸik downloader'lar saÄŸlar.

### HÄ±zlÄ± BaÅŸlangÄ±Ã§

```bash
# TÃ¼m mevcut veri setlerini listele
python scripts/download_datasets.py --list

# Belirli bir veri setini indir
python scripts/download_datasets.py --dataset lfw --root ./datasets

# Birden fazla veri setini indir
python scripts/download_datasets.py --dataset lfw socofing librispeech --root ./datasets

# LibriSpeech iÃ§in Ã¶zel subset
python scripts/download_datasets.py --dataset librispeech --subset dev-clean
```

### Python'dan KullanÄ±m

```python
from biognn.data.downloaders import get_downloader

# LFW veri setini indir
downloader = get_downloader('lfw', root='./datasets')
dataset_path = downloader.download()

# LibriSpeech subset indir
from biognn.data.downloaders import LibriSpeechDownloader
downloader = LibriSpeechDownloader(root='./datasets', subset='dev-clean')
dataset_path = downloader.download()

# SOCOFing (Kaggle - API credentials gerekli)
from biognn.data.downloaders import SOCOFingDownloader
downloader = SOCOFingDownloader(root='./datasets')
dataset_path = downloader.download()
```

### Otomatik Ä°ndirme Destekleyen Veri Setleri

| Veri Seti | Boyut | Ä°ndirme TÃ¼rÃ¼ | Ek Gereksinim |
|-----------|-------|--------------|---------------|
| **LFW** | ~200MB | Otomatik | Yok |
| **CelebA** | ~1.3GB | Otomatik | Google Drive (manuel gerekebilir) |
| **SOCOFing** | ~1GB | Kaggle API | Kaggle credentials |
| **LibriSpeech** | 340MB-60GB | Otomatik | Yok |

### Manuel Ä°ndirme Gerektiren Veri Setleri

BazÄ± veri setleri kayÄ±t ve anlaÅŸma gerektirdiÄŸi iÃ§in manuel indirme talimatlarÄ± gÃ¶sterilir:

```bash
# Talimatleri gÃ¶ster
python scripts/download_datasets.py --dataset casia-webface --show-instructions
python scripts/download_datasets.py --dataset voxceleb --show-instructions
python scripts/download_datasets.py --dataset fvc2004 --show-instructions
```

### Kaggle Veri Setleri Ä°Ã§in Kurulum

SOCOFing gibi Kaggle veri setleri iÃ§in:

```bash
# Kaggle API'yi kur
pip install kaggle

# Kaggle credentials yapÄ±landÄ±r
# 1. https://www.kaggle.com/settings/account adresine git
# 2. "Create New API Token" tÄ±kla
# 3. kaggle.json dosyasÄ±nÄ± ~/.kaggle/ dizinine yerleÅŸtir
# 4. Ä°zinleri ayarla
chmod 600 ~/.kaggle/kaggle.json

# ArtÄ±k Kaggle veri setlerini indirebilirsiniz
python scripts/download_datasets.py --dataset socofing
```

## ğŸ—‚ï¸ Ã–nerilen AÃ§Ä±k Veri Setleri

### 1. YÃ¼z TanÄ±ma

#### CASIA-WebFace
- **AÃ§Ä±klama**: 10,575 kiÅŸiye ait 494,414 yÃ¼z gÃ¶rÃ¼ntÃ¼sÃ¼
- **Ä°ndirme**: http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html
- **Lisans**: Research use only
- **Format**: JPEG images
- **KullanÄ±m**: YÃ¼z doÄŸrulama ve tanÄ±ma iÃ§in en popÃ¼ler veri setlerinden biri

#### LFW (Labeled Faces in the Wild)
- **AÃ§Ä±klama**: 5,749 kiÅŸiye ait 13,233 gÃ¶rÃ¼ntÃ¼
- **Ä°ndirme**: http://vis-www.cs.umass.edu/lfw/
- **Lisans**: Public domain
- **KullanÄ±m**: Benchmark iÃ§in ideal

#### CelebA
- **AÃ§Ä±klama**: 10,177 Ã¼nlÃ¼ye ait 202,599 gÃ¶rÃ¼ntÃ¼
- **Ä°ndirme**: http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html
- **Lisans**: Non-commercial research purposes
- **Ã–zellikler**: 40 binary attribute annotation

### 2. Parmak Ä°zi

#### FVC2004 (Fingerprint Verification Competition)
- **AÃ§Ä±klama**: 4 farklÄ± veri seti (DB1-DB4)
- **Ä°ndirme**: http://bias.csr.unibo.it/fvc2004/
- **Lisans**: Research use
- **Format**: TIFF images (500 DPI)
- **KullanÄ±m**: Parmak izi doÄŸrulama benchmark'Ä±

#### SOCOFing
- **AÃ§Ä±klama**: 6,000 parmak izi gÃ¶rÃ¼ntÃ¼sÃ¼
- **Ä°ndirme**: https://www.kaggle.com/datasets/ruizgara/socofing
- **Lisans**: Kaggle license
- **Format**: BMP images
- **Ã–zellikler**: GerÃ§ek ve deÄŸiÅŸtirilmiÅŸ parmak izleri

### 3. Iris TanÄ±ma

#### CASIA-Iris-V4
- **AÃ§Ä±klama**: Birden fazla iris veri seti (Interval, Lamp, Twins, Distance, Synthetic)
- **Ä°ndirme**: http://biometrics.idealtest.org/
- **Lisans**: Research use only
- **Format**: JPEG images
- **Ã–zellikler**: FarklÄ± yakalama koÅŸullarÄ±

#### UBIRIS
- **AÃ§Ä±klama**: 241 kiÅŸiye ait iris gÃ¶rÃ¼ntÃ¼leri
- **Ä°ndirme**: http://iris.di.ubi.pt/
- **Lisans**: Free for research
- **Format**: JPEG images
- **Ã–zellikler**: GÃ¼rÃ¼ltÃ¼lÃ¼ ve temiz versiyonlar

### 4. Ses/KonuÅŸmacÄ± TanÄ±ma

#### VoxCeleb1/2
- **AÃ§Ä±klama**: 7,000+ konuÅŸmacÄ±ya ait 1M+ ses kayÄ±tlarÄ±
- **Ä°ndirme**: https://www.robots.ox.ac.uk/~vgg/data/voxceleb/
- **Lisans**: Free for research
- **Format**: M4A audio files
- **KullanÄ±m**: KonuÅŸmacÄ± doÄŸrulama ve tanÄ±ma

#### LibriSpeech
- **AÃ§Ä±klama**: 1,000 saatlik Ä°ngilizce konuÅŸma
- **Ä°ndirme**: http://www.openslr.org/12
- **Lisans**: CC BY 4.0
- **Format**: FLAC audio files

## ğŸ“ Veri Organizasyonu

### Ã–nerilen Dizin YapÄ±sÄ±

```
datasets/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ subject_001/
â”‚   â”‚   â”œâ”€â”€ face_001.jpg        # Ä°lk yÃ¼z Ã¶rneÄŸi
â”‚   â”‚   â”œâ”€â”€ face_002.jpg        # Ä°kinci yÃ¼z Ã¶rneÄŸi
â”‚   â”‚   â”œâ”€â”€ fingerprint_001.png # Parmak izi
â”‚   â”‚   â”œâ”€â”€ iris_001.png        # Iris
â”‚   â”‚   â””â”€â”€ voice_001.wav       # Ses kaydÄ±
â”‚   â”œâ”€â”€ subject_002/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ val/
â”‚   â””â”€â”€ ... (aynÄ± yapÄ±)
â””â”€â”€ test/
    â””â”€â”€ ... (aynÄ± yapÄ±)
```

### Dosya AdlandÄ±rma KurallarÄ±

- **Format**: `{modality}_{index}.{extension}`
- **Modalite isimleri**: `face`, `fingerprint`, `iris`, `voice`
- **Index**: 3 haneli numara (001, 002, ...)
- **Extension**: jpg/png (gÃ¶rÃ¼ntÃ¼), wav/flac (ses)

### Ã–rnek

```
subject_042/
â”œâ”€â”€ face_001.jpg
â”œâ”€â”€ face_002.jpg
â”œâ”€â”€ face_003.jpg
â”œâ”€â”€ fingerprint_001.png
â”œâ”€â”€ fingerprint_002.png
â”œâ”€â”€ iris_001.png
â””â”€â”€ voice_001.wav
```

## ğŸ”§ Veri Preprocessing

### YÃ¼z GÃ¶rÃ¼ntÃ¼leri

```python
from biognn.data import FaceTransform

transform = FaceTransform(
    img_size=(112, 112),
    augment=True,  # Training iÃ§in
    normalize=True
)

# KullanÄ±m
face_img = Image.open('face.jpg')
face_tensor = transform(face_img)  # [3, 112, 112]
```

### Parmak Ä°zi

```python
from biognn.data import FingerprintTransform

transform = FingerprintTransform(
    img_size=(96, 96),
    augment=True,
    normalize=True
)
```

### Iris

```python
from biognn.data import IrisTransform

transform = IrisTransform(
    img_size=(64, 256),  # Unwrapped iris boyutu
    augment=True,
    normalize=True
)
```

### Ses

```python
from biognn.data import VoiceTransform

transform = VoiceTransform(
    sample_rate=16000,
    n_mfcc=40,
    n_fft=512,
    hop_length=160,
    augment=True,
    max_length=16000*3  # 3 saniye
)

# MFCC features Ã§Ä±karÄ±r: [40, time_frames]
```

## ğŸ“ Veri Seti OluÅŸturma

### 1. Kendi Verilerinizi Organize Edin

```bash
# Script kullanarak organize edin
python scripts/organize_dataset.py \
    --input /path/to/raw/data \
    --output ./datasets \
    --train_ratio 0.7 \
    --val_ratio 0.15 \
    --test_ratio 0.15
```

### 2. Dataset SÄ±nÄ±fÄ± OluÅŸturun

```python
from biognn.data import MultimodalBiometricDataset

class MyDataset(MultimodalBiometricDataset):
    def _load_data(self):
        # Veri yÃ¼kleme mantÄ±ÄŸÄ±
        pass
    
    def __getitem__(self, idx):
        # Bir Ã¶rnek dÃ¶ndÃ¼r
        pass
```

### 3. DoÄŸrulama

```python
# Veri setini test edin
dataset = MyDataset(root='./datasets', split='train')
print(f"Dataset size: {len(dataset)}")

# Ä°lk Ã¶rneÄŸi kontrol edin
sample = dataset[0]
print(f"Subject ID: {sample.subject_id}")
print(f"Modalities: {sample.get_available_modalities()}")

for mod, data in sample.modalities.items():
    print(f"  {mod}: {data.shape}")
```

## ğŸ¯ Veri ArtÄ±rma (Augmentation)

### EÄŸitim Ä°Ã§in Ã–neriler

```python
# Agresif augmentation
train_transforms = {
    'face': FaceTransform(augment=True),
    'fingerprint': FingerprintTransform(augment=True),
    'iris': IrisTransform(augment=True),
    'voice': VoiceTransform(augment=True)
}

# Validation/test iÃ§in augmentation YOK
val_transforms = {
    'face': FaceTransform(augment=False),
    'fingerprint': FingerprintTransform(augment=False),
    'iris': IrisTransform(augment=False),
    'voice': VoiceTransform(augment=False)
}
```

## ğŸ“Š Veri Ä°statistikleri

Veri setinizi analiz edin:

```python
# Dataset istatistikleri
from collections import Counter

subject_counts = Counter()
modality_counts = {mod: 0 for mod in ['face', 'fingerprint', 'iris', 'voice']}

for idx in range(len(dataset)):
    sample = dataset[idx]
    subject_counts[sample.subject_id] += 1
    
    for mod in sample.get_available_modalities():
        modality_counts[mod] += 1

print(f"Unique subjects: {len(subject_counts)}")
print(f"Avg samples per subject: {np.mean(list(subject_counts.values())):.2f}")
print(f"Modality coverage:")
for mod, count in modality_counts.items():
    print(f"  {mod}: {count} ({count/len(dataset)*100:.1f}%)")
```

## âš ï¸ YaygÄ±n Hatalar ve Ã‡Ã¶zÃ¼mleri

### 1. Dosya BulunamadÄ±

**Hata**: `FileNotFoundError: Data directory not found`

**Ã‡Ã¶zÃ¼m**: Dizin yapÄ±sÄ±nÄ± kontrol edin:
```bash
ls -R datasets/train/subject_001/
```

### 2. Boyut UyumsuzluÄŸu

**Hata**: `RuntimeError: Expected 3D tensor, got 2D`

**Ã‡Ã¶zÃ¼m**: Transform'larÄ± doÄŸru uygulayÄ±n:
```python
# YanlÄ±ÅŸ
img = np.array(Image.open('face.jpg'))  # NumPy array

# DoÄŸru
img = Image.open('face.jpg')  # PIL Image
img = transform(img)  # Tensor'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r
```

### 3. Ses Format HatasÄ±

**Hata**: `soundfile.LibsndfileError: Format not recognised`

**Ã‡Ã¶zÃ¼m**: Ses dosyasÄ±nÄ± dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n:
```bash
# ffmpeg kullanarak WAV'a dÃ¶nÃ¼ÅŸtÃ¼r
ffmpeg -i input.mp3 -ar 16000 -ac 1 output.wav
```

## ğŸ“š Ek Kaynaklar

- **Veri artÄ±rma teknikleri**: `biognn/data/transforms.py`
- **Feature extraction**: `biognn/data/feature_extractors.py`
- **Ã–rnek dataset**: `biognn/data/example_dataset.py`

## ğŸ”— Linkler

- NIST Biometric Datasets: https://www.nist.gov/itl/iad/image-group/biometric-data
- IEEE Biometrics Council: https://ieee-biometrics.org/
- Biometric Evaluation: https://www.iso.org/standard/78160.html
