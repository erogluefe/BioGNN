# BioGNN - KullanÄ±m KÄ±lavuzu

Bu dokÃ¼mantasyon, BioGNN projesini kullanmaya baÅŸlamak iÃ§in gereken tÃ¼m adÄ±mlarÄ± iÃ§erir.

## ğŸ“‹ Ä°Ã§indekiler

1. [Gereksinimler](#gereksinimler)
2. [Kurulum](#kurulum)
3. [Veri Seti HazÄ±rlama](#veri-seti-hazÄ±rlama)
4. [HÄ±zlÄ± BaÅŸlangÄ±Ã§](#hÄ±zlÄ±-baÅŸlangÄ±Ã§)
5. [Kendi Veri Setinizi Kullanma](#kendi-veri-setinizi-kullanma)
6. [Model EÄŸitimi](#model-eÄŸitimi)
7. [DeÄŸerlendirme](#deÄŸerlendirme)
8. [SÄ±k Sorulan Sorular](#sÄ±k-sorulan-sorular)

## âš™ï¸ Gereksinimler

### YazÄ±lÄ±m Gereksinimleri

- Python 3.8 veya Ã¼zeri
- CUDA 11.0+ (GPU kullanÄ±mÄ± iÃ§in - opsiyonel ama Ã¶nerilir)
- 8GB+ RAM (16GB Ã¶nerilir)
- 10GB+ disk alanÄ±

### DonanÄ±m Ã–nerileri

**Minimum**:
- CPU: 4 core
- RAM: 8GB
- GPU: NVIDIA GPU (4GB+ VRAM)

**Ã–nerilen**:
- CPU: 8+ core
- RAM: 16GB+
- GPU: NVIDIA RTX 3090 / A100 (12GB+ VRAM)

## ğŸš€ Kurulum

### 1. Repository'yi KlonlayÄ±n

```bash
git clone https://github.com/erogluefe/BioGNN.git
cd BioGNN
```

### 2. Sanal Ortam OluÅŸturun

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# veya
venv\Scripts\activate  # Windows
```

### 3. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin

```bash
# Temel baÄŸÄ±mlÄ±lÄ±klar
pip install -r requirements.txt

# Paketi editable modda yÃ¼kleyin
pip install -e .

# PyTorch Geometric (CUDA 11.8 iÃ§in)
pip install torch-geometric
pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv \
    -f https://data.pyg.org/whl/torch-2.0.0+cu118.html

# CPU-only kullanÄ±yorsanÄ±z:
pip install torch-geometric
pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv \
    -f https://data.pyg.org/whl/torch-2.0.0+cpu.html
```

### 4. Kurulumu DoÄŸrulayÄ±n

```bash
python -c "import biognn; print('BioGNN version:', biognn.__version__)"
python -c "import torch_geometric; print('PyG installed successfully')"
```

## ğŸ“ Veri Seti HazÄ±rlama

### SeÃ§enek 1: Sentetik Veri (Test Ä°Ã§in)

Test ve geliÅŸtirme iÃ§in sentetik veri kullanabilirsiniz:

```bash
# HÄ±zlÄ± baÅŸlangÄ±Ã§ Ã¶rneÄŸini Ã§alÄ±ÅŸtÄ±rÄ±n
python examples/quickstart.py
```

Bu, gerÃ§ek veri olmadan sistemi test etmenizi saÄŸlar.

### SeÃ§enek 2: GerÃ§ek Veri Seti Kullanma

#### Ã–nerilen AÃ§Ä±k Veri Setleri

1. **YÃ¼z TanÄ±ma**:
   - [CASIA-WebFace](http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html) (10,575 kiÅŸi)
   - [LFW (Labeled Faces in the Wild)](http://vis-www.cs.umass.edu/lfw/)
   - [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)

2. **Parmak Ä°zi**:
   - [FVC2004](http://bias.csr.unibo.it/fvc2004/) (Fingerprint Verification Competition)
   - [SOCOFing](https://www.kaggle.com/datasets/ruizgara/socofing)

3. **Iris**:
   - [CASIA-Iris-V4](http://biometrics.idealtest.org/)
   - [UBIRIS](http://iris.di.ubi.pt/)

4. **Ses**:
   - [VoxCeleb1/2](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/)
   - [LibriSpeech](http://www.openslr.org/12)

#### Veri Organizasyonu

Veri setinizi ÅŸu yapÄ±da organize edin:

```
datasets/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ subject_001/
â”‚   â”‚   â”œâ”€â”€ face_001.jpg
â”‚   â”‚   â”œâ”€â”€ face_002.jpg
â”‚   â”‚   â”œâ”€â”€ fingerprint_001.png
â”‚   â”‚   â”œâ”€â”€ iris_001.png
â”‚   â”‚   â””â”€â”€ voice_001.wav
â”‚   â”œâ”€â”€ subject_002/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ val/
â”‚   â””â”€â”€ ... (aynÄ± yapÄ±)
â””â”€â”€ test/
    â””â”€â”€ ... (aynÄ± yapÄ±)
```

**Not**: Her modalite iÃ§in dosya isimleri `{modality}_{index}.{ext}` formatÄ±nda olmalÄ±.

## ğŸƒ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Sentetik Veri ile Test

```bash
# HÄ±zlÄ± baÅŸlangÄ±Ã§ scripti
python examples/quickstart.py
```

Bu script:
- âœ… Sentetik veri oluÅŸturur
- âœ… Model eÄŸitir (3 epoch)
- âœ… DeÄŸerlendirme yapar
- âœ… ROC ve DET eÄŸrileri Ã§izer

### GerÃ§ek Veri ile EÄŸitim

```bash
# VarsayÄ±lan konfigÃ¼rasyonla
python train.py --config configs/default_config.yaml

# GAT modeliyle
python train.py --config configs/default_config.yaml --gpu 0
```

## ğŸ”§ Kendi Veri Setinizi Kullanma

### 1. Dataset SÄ±nÄ±fÄ± OluÅŸturun

`biognn/data/example_dataset.py` dosyasÄ±nÄ± template olarak kullanÄ±n:

```python
from biognn.data import MultimodalBiometricDataset, BiometricSample
from biognn.data.example_dataset import ExampleMultimodalDataset

# Kendi dataset sÄ±nÄ±fÄ±nÄ±zÄ± oluÅŸturun
class MyDataset(ExampleMultimodalDataset):
    def __init__(self, root, modalities, split='train', transform=None):
        super().__init__(root, modalities, split, transform, download=False)

    def _load_data(self):
        # Kendi veri yÃ¼kleme mantÄ±ÄŸÄ±nÄ±zÄ± buraya yazÄ±n
        pass
```

### 2. Dataset'i KullanÄ±n

```python
from biognn.data import get_default_transforms

# Transforms oluÅŸtur
transforms = {
    mod: get_default_transforms(mod, augment=True)
    for mod in ['face', 'fingerprint', 'iris', 'voice']
}

# Dataset oluÅŸtur
dataset = MyDataset(
    root='./datasets',
    modalities=['face', 'fingerprint', 'iris', 'voice'],
    split='train',
    transform=transforms
)

# DataLoader oluÅŸtur
from torch.utils.data import DataLoader
loader = DataLoader(dataset, batch_size=32, shuffle=True)
```

## ğŸ“ Model EÄŸitimi

### Basit EÄŸitim

```python
from biognn.fusion import MultimodalBiometricFusion
from biognn.utils import Trainer

# Model oluÅŸtur
model = MultimodalBiometricFusion(
    modalities=['face', 'fingerprint', 'iris', 'voice'],
    feature_dim=512,
    gnn_type='gat',
    gnn_config={'hidden_dims': [256, 128], 'heads': [4, 4]}
)

# Trainer oluÅŸtur
trainer = Trainer(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    device='cuda'
)

# EÄŸit
trainer.train(num_epochs=100, save_best=True)
```

### GeliÅŸmiÅŸ EÄŸitim (Contrastive Learning)

```python
from biognn.utils import CombinedLoss

# Combined loss kullan
criterion = CombinedLoss(
    num_classes=1000,
    feature_dim=512,
    use_triplet=True,
    use_center=True
)

# Trainer'da kullan
trainer = Trainer(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    criterion=criterion,
    device='cuda'
)
```

### Multi-Task Learning

```python
from biognn.models import MultiTaskBiometricModel

model = MultiTaskBiometricModel(
    modalities=['face', 'fingerprint', 'iris', 'voice'],
    use_quality_task=True,
    use_liveness_task=True
)

# EÄŸitim sÄ±rasÄ±nda 3 loss hesaplanÄ±r:
# 1. Verification loss
# 2. Quality estimation loss
# 3. Liveness detection loss
```

## ğŸ“Š DeÄŸerlendirme

### Temel DeÄŸerlendirme

```python
from biognn.evaluation import BiometricEvaluator

evaluator = BiometricEvaluator()
results = evaluator.evaluate(y_true, y_scores)
evaluator.print_summary()

# GÃ¶rselleÅŸtirmeler
evaluator.plot_roc_curve(y_true, y_scores, save_path='roc.png')
evaluator.plot_det_curve(y_true, y_scores, save_path='det.png')
evaluator.plot_confusion_matrix(y_true, y_pred, save_path='cm.png')
```

### CMC EÄŸrisi (Identification)

```python
from biognn.evaluation import CMCEvaluator

evaluator = CMCEvaluator(max_rank=20)
results = evaluator.evaluate(
    query_features,
    gallery_features,
    query_labels,
    gallery_labels
)

evaluator.print_summary()  # Rank-1, Rank-5, Rank-10
evaluator.plot(save_path='cmc.png')
```

### Ablasyon Ã‡alÄ±ÅŸmasÄ±

```bash
# Modalite ablasyonu
python scripts/ablation_study.py \
    --study modality \
    --checkpoint best_model.pth \
    --output results/ablation

# Mimari ablasyonu
python scripts/ablation_study.py \
    --study architecture \
    --checkpoint best_model.pth
```

### Ä°statistiksel Analiz

```bash
# Cross-validation
python scripts/statistical_analysis.py \
    --analysis cv \
    --n_folds 5

# Leave-one-subject-out
python scripts/statistical_analysis.py \
    --analysis loso
```

## â“ SÄ±k Sorulan Sorular

### Q: Veri setim sadece 2 modalite iÃ§eriyor, kullanabilir miyim?

**A**: Evet! Model herhangi bir modalite kombinasyonuyla Ã§alÄ±ÅŸÄ±r:

```python
model = MultimodalBiometricFusion(
    modalities=['face', 'fingerprint'],  # Sadece 2 modalite
    feature_dim=512,
    gnn_type='gat'
)
```

### Q: GPU olmadan Ã§alÄ±ÅŸtÄ±rabilir miyim?

**A**: Evet, ama yavaÅŸ olacaktÄ±r. CPU kullanÄ±mÄ± iÃ§in:

```python
trainer = Trainer(
    model=model,
    train_loader=train_loader,
    device='cpu',
    use_amp=False  # AMP sadece GPU'da Ã§alÄ±ÅŸÄ±r
)
```

### Q: Kendi feature extractor'Ä±mÄ± kullanabilir miyim?

**A**: Evet:

```python
from biognn.data.feature_extractors import FaceFeatureExtractor

# Kendi extractor'Ä±nÄ±z
class MyFaceExtractor(FaceFeatureExtractor):
    def __init__(self, feature_dim=512):
        super().__init__(
            backbone='resnet50',
            pretrained=True,
            feature_dim=feature_dim
        )

    # forward() metodunu override edebilirsiniz
```

### Q: EÄŸitim Ã§ok yavaÅŸ, nasÄ±l hÄ±zlandÄ±rabilirim?

**A**: BirkaÃ§ Ã¶neri:

1. **Batch size'Ä± artÄ±rÄ±n**: `batch_size=64` (GPU belleÄŸi yetiyorsa)
2. **AMP kullanÄ±n**: `use_amp=True`
3. **Num workers artÄ±rÄ±n**: `DataLoader(..., num_workers=4)`
4. **Daha kÃ¼Ã§Ã¼k model**: `hidden_dims=[128, 64]`
5. **Backbone freeze**: `freeze_backbone=True`

### Q: Out of memory hatasÄ± alÄ±yorum

**A**: Ã‡Ã¶zÃ¼mler:

1. Batch size'Ä± azaltÄ±n: `batch_size=8`
2. Feature dimension azaltÄ±n: `feature_dim=256`
3. Gradient accumulation kullanÄ±n
4. Mixed precision training: `use_amp=True`

### Q: Pretrained modeller var mÄ±?

**A**: Åu anda hayÄ±r. Ancak feature extractor'lar (ResNet, MobileNet, DenseNet) ImageNet pretrained weights kullanÄ±r:

```python
model = FaceFeatureExtractor(
    backbone='resnet50',
    pretrained=True  # ImageNet weights
)
```

### Q: Veri setim dengesiz (Ã§ok fazla genuine, az impostor)

**A**: `VerificationPairDataset`'te ratio'yu ayarlayÄ±n:

```python
dataset = VerificationPairDataset(
    base_dataset=base,
    num_pairs=10000,
    genuine_ratio=0.3  # %30 genuine, %70 impostor
)
```

## ğŸ“š Ek Kaynaklar

- **DetaylÄ± API DokÃ¼mantasyonu**: Kod iÃ§indeki docstring'leri okuyun
- **Ã–rnek KonfigÃ¼rasyonlar**: `configs/` klasÃ¶rÃ¼
- **Ã–rnek Scriptler**: `examples/` ve `scripts/` klasÃ¶rleri
- **AraÅŸtÄ±rma Makalesi**: (YakÄ±nda eklenecek)

## ğŸ†˜ YardÄ±m

Sorun yaÅŸÄ±yorsanÄ±z:

1. GitHub Issues'a bakÄ±n
2. Yeni issue aÃ§Ä±n (hata raporu veya Ã¶zellik isteÄŸi)
3. DokÃ¼mantasyonu kontrol edin

## ğŸ“ KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! Pull request gÃ¶ndermeden Ã¶nce lÃ¼tfen:

1. Kodun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun
2. Testler yazÄ±n (mÃ¼mkÃ¼nse)
3. DokÃ¼mantasyon ekleyin
4. Kod stiline uyun

---

**Not**: Bu proje aktif geliÅŸtirme aÅŸamasÄ±nda. Ã–zellikler ve API deÄŸiÅŸebilir.
